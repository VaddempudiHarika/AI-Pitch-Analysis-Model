# Install required libraries
!pip install requests

# Import libraries
import json
import re
import time
from google.colab import files
import requests

# Set your Hugging Face API key
HUGGINGFACE_API_KEY = "your_huggingface_api_key"  # Replace with your actual API key
HUGGINGFACE_API_URL = "https://api-inference.huggingface.co/models/gpt2"  # Example endpoint

# Load JSON data with error handling
def load_json_data(json_path):
    """
    Loads JSON data from a file with error handling.
    """
    try:
        with open(json_path, "r") as file:
            data = json.load(file)
        return data
    except json.JSONDecodeError as e:
        print(f"JSONDecodeError: {e}")
        print(f"Error occurred at line {e.lineno}, column {e.colno}: {e.msg}")
        return None
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Step 1: Preprocessing
def preprocess_data(entry):
    """
    Preprocesses the JSON entry to extract relevant information.
    """
    processed_data = {
        "Name": entry.get("Name", ""),
        "Overview": entry.get("Overview", ""),
        "Stage": entry.get("Stage", ""),
        "Industry": entry.get("Industry", ""),
        "Cheque_range": entry.get("Cheque_range", ""),
        "Type": entry.get("Type", ""),
        "Global_HQ": entry.get("Global_HQ", ""),
        "Countries": entry.get("Countries", ""),
    }
    return processed_data

# Step 2: Feature Engineering
def identify_sections(processed_data):
    """
    Identifies key sections in the JSON data.
    """
    sections = {
        "Overview": processed_data.get("Overview", ""),
        "Stage": processed_data.get("Stage", ""),
        "Industry": processed_data.get("Industry", ""),
        "Cheque_range": processed_data.get("Cheque_range", ""),
        "Type": processed_data.get("Type", ""),
        "Global_HQ": processed_data.get("Global_HQ", ""),
        "Countries": processed_data.get("Countries", ""),
    }
    return sections

# Step 3: Scoring Model with Hugging Face API
def evaluate_section(section_text, section_name):
    """
    Evaluates the quality of a section using Hugging Face API.
    """
    prompt = f"Evaluate the {section_name} section of a startup pitch. Provide a score (0-10) and feedback:\n\n{section_text}"
    
    # Prepare the API request payload
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_length": 150,
            "temperature": 0.7
        }
    }
    
    # Make the API request
    headers = {
        "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
        "Content-Type": "application/json"
    }
    response = requests.post(HUGGINGFACE_API_URL, json=payload, headers=headers)
    
    if response.status_code == 200:
        feedback = response.json()[0]["generated_text"].strip()
        score = re.search(r'\d+', feedback).group()  # Extract the first number as the score
        return int(score), feedback
    else:
        print(f"Error: {response.status_code} - {response.text}")
        return 0, "Failed to evaluate section."

def calculate_pitch_score(sections):
    """
    Calculates the overall pitch score based on section scores.
    """
    weights = {
        "Overview": 0.3,
        "Stage": 0.2,
        "Industry": 0.15,
        "Cheque_range": 0.15,
        "Type": 0.1,
        "Global_HQ": 0.05,
        "Countries": 0.05,
    }
    total_score = 0
    feedback = {}

    for section_name, section_text in sections.items():
        if section_text:
            score, section_feedback = evaluate_section(section_text, section_name)
            total_score += score * weights[section_name]
            feedback[section_name] = section_feedback
        else:
            feedback[section_name] = f"{section_name} section not found or incomplete."

    return int(total_score * 10), feedback  # Scale to 0-100

# Step 4: Strength & Weakness Analysis
def analyze_strengths_weaknesses(feedback):
    """
    Analyzes strengths and weaknesses based on feedback.
    """
    strengths = []
    weaknesses = []

    for section, section_feedback in feedback.items():
        if "not found" in section_feedback.lower():
            weaknesses.append(f"{section} section is missing or incomplete.")
        elif int(re.search(r'\d+', section_feedback).group()) >= 7:
            strengths.append(f"{section} is strong: {section_feedback}")
        else:
            weaknesses.append(f"{section} needs improvement: {section_feedback}")

    return strengths, weaknesses

# Step 5: Output
def analyze_pitch_data(json_path):
    """
    Analyzes a JSON dataset and provides a pitch score, strengths, and weaknesses.
    """
    # Load JSON data
    data = load_json_data(json_path)
    if data is None:
        return  # Exit if JSON data could not be loaded

    # Process each entry in the JSON data
    for entry in data:
        print(f"\nAnalyzing: {entry.get('Name', 'Unnamed Entry')}")
        
        # Preprocess data
        processed_data = preprocess_data(entry)

        # Identify sections
        sections = identify_sections(processed_data)

        # Calculate pitch score
        pitch_score, feedback = calculate_pitch_score(sections)

        # Analyze strengths and weaknesses
        strengths, weaknesses = analyze_strengths_weaknesses(feedback)

        # Display results
        print(f"Pitch Score: {pitch_score}/100")
        print("\nStrengths:")
        for strength in strengths:
            print(f"- {strength}")
        print("\nWeaknesses:")
        for weakness in weaknesses:
            print(f"- {weakness}")

# Example Usage
if __name__ == "__main__":
    # Upload the JSON file
    uploaded = files.upload()
    json_path = list(uploaded.keys())[0]  # Use the uploaded file's name

    # Analyze the pitch data
    analyze_pitch_data(json_path)
